{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3619f",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "boston = pd.read_csv('housing.data', header=None, delim_whitespace = True, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558fd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of the data\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the data\n",
    "boston.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a37ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the info of the dataframe for basic checks on the number of data entries, data type, etc\n",
    "boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification of missing data\n",
    "boston.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f148e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the basic statistics of the dataframe\n",
    "boston.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the distribution of the output variable\n",
    "sns.distplot(boston['MEDV'])\n",
    "plt.show()\n",
    "\n",
    "# the dependent variable follows a normal distribution"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a460cb1b",
   "metadata": {},
   "source": [
    "Based on the data preprocessing checks done, there is no further need to modify the dataset as there is no missing values, the data is in numerical format (no structural errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea30e7",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83a88365",
   "metadata": {},
   "source": [
    "y = b0 + b1x1 + b2x2 + b3x3 + b4x4 + b5x5 + b6x6 + b7x7 + b8x8 + b9x9 + b10x10 + b11x11 + b12x12 + b13x13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23b5c9",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "x = boston[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']]\n",
    "\n",
    "# Putting response variable to y\n",
    "y = boston['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check p-value of variables\n",
    "import statsmodels.api as sm          # Importing statsmodels\n",
    "x = sm.add_constant(x)    # Adding a constant column to our dataframe\n",
    "# create a first fitted model\n",
    "lm = sm.OLS(y,x).fit()\n",
    "# Summary of linear model\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f747e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for calculating vif value\n",
    "def vif_cal(input_data, dependent_col):\n",
    "    vif_df = pd.DataFrame( columns = ['Var', 'Vif'])\n",
    "    x_vars=input_data.drop([dependent_col], axis=1)\n",
    "    xvar_names=x_vars.columns\n",
    "    for i in range(0,xvar_names.shape[0]):\n",
    "        y=x_vars[xvar_names[i]] \n",
    "        x=x_vars[xvar_names.drop(xvar_names[i])]\n",
    "        rsq=sm.OLS(y,x).fit().rsquared \n",
    "        vif=round(1/(1-rsq),2)\n",
    "        vif_df.loc[i] = [xvar_names[i], vif]\n",
    "    return vif_df.sort_values(by = 'Vif', axis=0, ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Vif value\n",
    "vif_cal(input_data=boston, dependent_col=\"MEDV\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07b6cd4c",
   "metadata": {},
   "source": [
    "Based on the variables with the lowest VIF and whose p-value is < 0.05 (i.e. significant), the 5 attributes chosen are CRIM (per capita crime rate), ZN (proportion of residential land zone lots), LSTAT (% lower status of the population), DIS (weighted distance to employment centers) and B (1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town). CHAS and RAD were excluded as they are categorical data (discrete values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d31990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting input variables 'B', 'DIS', 'LSTAT', 'ZN', 'CRIM' against the output variable 'MEDV'\n",
    "boston_5 = boston[['B', 'DIS', 'LSTAT', 'ZN', 'CRIM', 'MEDV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9acc28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the correlation matrix\n",
    "plt.figure(figsize=(15, 10))\n",
    "correlation_matrix = boston_5.corr()\n",
    "sns.heatmap(data=correlation_matrix, annot=True, annot_kws={\"size\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99baeffb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(boston_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a57347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting LSTAT vs output variable MEDV to show example of correlated relationship\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(boston['MEDV'], boston['LSTAT'])\n",
    "\n",
    "plt.title(\"Plot of LSTAT VS MEDV\")\n",
    "plt.xlabel('MEDV')\n",
    "plt.ylabel('LSTAT')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting output variable MEDV vs DIS to show example of not highly correlated relationship\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(boston['MEDV'], boston['DIS'])\n",
    "\n",
    "plt.title(\"Plot of DIS VS MEDV\")\n",
    "plt.xlabel('MEDV')\n",
    "plt.ylabel('DIS')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e666fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting output variable MEDV vs DIS to show example of not highly correlated relationship\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(boston['MEDV'], boston['ZN'])\n",
    "\n",
    "plt.title(\"Plot of ZN VS MEDV\")\n",
    "plt.xlabel('MEDV')\n",
    "plt.ylabel('ZN')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f5571",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE funtion = square root of MSE\n",
    "def RMSE(y, y_pred):\n",
    "    MSE = np.sum((y_pred - y)**2)/y.shape[0]\n",
    "    RMSE = MSE**0.5\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 funtion = (1 - RSS/ TSS)\n",
    "def r2(y, y_pred):\n",
    "    RSS = np.sum(((y - y_pred)**2))\n",
    "    TSS = np.sum(((y - y.mean())**2))\n",
    "    r2 = 1-(RSS/TSS)\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995de978",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff395d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  cal_cost(theta,X,y):\n",
    "    '''\n",
    "    theta = coeff vector\n",
    "    X     = input dataset (13 attributes)\n",
    "    y     = output (1 variable)\n",
    "    '''\n",
    "    m = len(y)\n",
    "    \n",
    "    prediction = np.dot(X,theta)\n",
    "    cost = 1/(2*m) * np.sum((prediction-y)**2)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,y,theta,learning_rate=0.01,iterations=100):\n",
    "    '''\n",
    "    X     = input dataset (13 attributes)\n",
    "    y     = output (1 variable)\n",
    "    theta = coeff vector\n",
    "    learning_rate = default value of 0.01\n",
    "    iterations = no of iterations\n",
    "    \n",
    "    Returns the final theta vector and array of cost history over no of iterations\n",
    "    '''\n",
    "    m = len(y)\n",
    "    \n",
    "    cost_history = np.zeros(iterations)\n",
    "    theta_history = np.zeros((iterations, len(theta)))\n",
    "    iter_counter = 0\n",
    "    threshold = 0.001 # threshold declaring convergence, i.e. change in loss < 0.001\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        prediction = np.dot(X,theta) # y_pred for each X data pt\n",
    "        d_theta = (1/m)*(np.dot(X.T,(prediction - y))) # gradient of theta\n",
    "        theta = theta - learning_rate*d_theta # new theta after first iteration\n",
    "        \n",
    "        theta_history[it,:] = theta.T\n",
    "        cost_history[it]  = cal_cost(theta,X,y)\n",
    "        \n",
    "        iter_counter += 1\n",
    "        \n",
    "        # uncomment the next 4 lines of code to run iterations until convergence threshold is reached\n",
    "#         if it > 0 and (cost_history[it-1]-cost_history[it])<threshold:\n",
    "#             break\n",
    "            \n",
    "#     print(\"No. of iterations ran:\", iter_counter)\n",
    "        \n",
    "    return theta, cost_history, theta_history"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5bdf363",
   "metadata": {},
   "source": [
    "for optimal value of alpha, refer to task 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91842404",
   "metadata": {},
   "source": [
    "## Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6245fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the 13 input features using (data-min)/(max-min)\n",
    "def dataNorm(X):\n",
    "    # Normalize the dataset\n",
    "    X_norm = np.array(X)    # initializes array X_norm with the same values as array x\n",
    "    for i in range(X.shape[1]-1):   # updates X_norm with the normalized input attributes\n",
    "        X_norm[:,i] = (X_norm[:,i]-np.min(X[:,i]))/(np.max(X[:,i])-np.min(X[:,i]))\n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = boston.to_numpy()\n",
    "boston_norm = dataNorm(boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcf7bd",
   "metadata": {},
   "source": [
    "## Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d315d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train (90%) and test (10%)\n",
    "def splitTT(X_norm, percentTrain):\n",
    "    # Split the dataset into training and testing using the train-and-test split method\n",
    "    percentTrain = float(percentTrain)\n",
    "    if percentTrain > 1 or percentTrain < 0:    #checks that expected portion of dataset for training the domain is (0..1)\n",
    "        print(\"Invalid training split size\")\n",
    "    else:\n",
    "        np.random.shuffle(X_norm)\n",
    "        X_train = X_norm[:round(percentTrain * X_norm.shape[0]), :]\n",
    "        X_test = X_norm[round(percentTrain * X_norm.shape[0]):, :]\n",
    "        X_split = [X_train, X_test]\n",
    "        return X_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db518f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split = splitTT(boston_norm,0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f49e4e",
   "metadata": {},
   "source": [
    "## Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the X train dataset\n",
    "X_train_ori = np.array(X_split[0][:,:-1])\n",
    "const_col = np.ones((len(X_train_ori),1)) # initialize a column of 1s\n",
    "X_train = np.append(const_col, X_train_ori, axis=1)  # adding a constant to the array\n",
    "\n",
    "# Extracting the y train dataset\n",
    "y_train_ori = np.array(X_split[0][:,-1])\n",
    "y_train = y_train_ori.reshape(-1, 1)\n",
    "\n",
    "# Extracting the X test dataset\n",
    "X_test_ori = np.array(X_split[1][:,:-1])\n",
    "const_col = np.ones((len(X_test_ori),1)) # initialize a column of 1s\n",
    "X_test = np.append(const_col, X_test_ori, axis=1) # adding a constant to the array\n",
    "\n",
    "# Extracting the y test dataset\n",
    "y_test_ori = np.array(X_split[1][:,-1])\n",
    "y_test = y_test_ori.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63011288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the learning rate and no. of iterations\n",
    "lr = 0.03\n",
    "n_iter = 20000\n",
    "\n",
    "# Initial values of parameters set as 0s\n",
    "theta = np.zeros((len(X_train[0]),1))\n",
    "\n",
    "# Running the gradient descent algorithm to compute the parameters\n",
    "theta,cost_history,theta_history = gradient_descent(X_train, y_train, theta, lr, n_iter)\n",
    "print('Final Cost (MSE):  {:0.3f}'.format(cost_history[-1]))\n",
    "\n",
    "# Calculating RMSE and R2 score using train dataset and computed parameters\n",
    "y_prediction_train = np.dot(X_train,theta)\n",
    "print(\"\\nTrain RMSE using user constructed linear regression model:\",\n",
    "round(RMSE(y_train, y_prediction_train),3))\n",
    "print(\"\\nTrain R2 using user constructed linear regression model:\",\n",
    "round(r2(y_train, y_prediction_train),3))\n",
    "\n",
    "# Calculating RMSE and R2 score using test dataset and computed parameters\n",
    "y_prediction_test = np.dot(X_test,theta)\n",
    "print(\"\\nTest RMSE using user constructed linear regression model:\",\n",
    "round(RMSE(y_test, y_prediction_test),3))\n",
    "print(\"\\nTest R2 using user constructed linear regression model:\",\n",
    "round(r2(y_test, y_prediction_test),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of Cost vs iterations\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(10000), cost_history[:10000,])\n",
    "plt.xticks(np.arange(0, 10001, 1000))\n",
    "\n",
    "plt.title(\"Cost vs iterations\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29dacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If iterations are too low\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(250), cost_history[:250], 'b.')\n",
    "\n",
    "# Min cost line based on experimental run. Value of y has to be changed accordingly run each run\n",
    "plt.axhline(y = 10.7, color = 'g', linestyle = '--', label = 'Min cost') \n",
    "\n",
    "plt.xticks(np.arange(0, 251, 50))\n",
    "plt.title(\"Cost vs iterations\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations threshold where graph converges\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(4000), cost_history[:4000])\n",
    "\n",
    "# Threshold and Min cost line based on experimental run. Value of x and y has to be changed accordingly for each run\n",
    "plt.axvline(x = 1994, color = 'g', linestyle = '--', label = 'threshold')\n",
    "plt.axhline(y = 10.7, color = 'r', linestyle = '--', label = 'Min cost')\n",
    "\n",
    "plt.xticks(np.arange(0, 4001, 500))\n",
    "plt.title(\"Cost vs iterations\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of predicted_y_train VS actual_y_train\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_train, y_prediction_train)\n",
    "\n",
    "p1 = min(min(y_train), min(y_prediction_train))\n",
    "p2 = max(max(y_train), max(y_prediction_train))\n",
    "\n",
    "plt.title(\"Plot of predicted_y_train VS actual_y_train\")\n",
    "plt.plot([p1, p2], [p1, p2], 'k--', lw=4)\n",
    "plt.xlabel('actual_y_train', fontsize=15)\n",
    "plt.ylabel('predicted_y_train', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of predicted_y_test VS actual_y_test\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_test, y_prediction_test)\n",
    "\n",
    "p1 = min(min(y_test), min(y_prediction_test))\n",
    "p2 = max(max(y_test), max(y_prediction_test))\n",
    "\n",
    "plt.title(\"Plot of predicted_y_test VS actual_y_test\")\n",
    "plt.plot([p1, p2], [p1, p2], 'k--', lw=4)\n",
    "plt.xlabel('actual_y_test', fontsize=15)\n",
    "plt.ylabel('predicted_y_test', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of different learning rate\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "n_iter = 500\n",
    "theta = np.zeros((len(X_train[0]),1))\n",
    "\n",
    "lr1 = 0.001\n",
    "theta1,cost_history1,theta_history1 = gradient_descent(X_train, y_train, theta, lr1, n_iter)\n",
    "plt.plot(range(n_iter), cost_history1, 'b.', label = 'learning rate 0.001')\n",
    "\n",
    "lr2 = 0.003\n",
    "theta2,cost_history2,theta_history2 = gradient_descent(X_train, y_train, theta, lr2, n_iter)\n",
    "plt.plot(range(n_iter), cost_history2, 'y.', label = 'learning rate 0.003')\n",
    "\n",
    "lr3 = 0.01\n",
    "theta3,cost_history3,theta_history3 = gradient_descent(X_train, y_train, theta, lr3, n_iter)\n",
    "plt.plot(range(n_iter), cost_history3, 'm.', label = 'learning rate 0.01')\n",
    "\n",
    "lr4 = 0.03\n",
    "theta4,cost_history4,theta_history4 = gradient_descent(X_train, y_train, theta, lr4, n_iter)\n",
    "plt.plot(range(n_iter), cost_history4, 'k.', label = 'learning rate 0.03')\n",
    "\n",
    "lr5 = 0.3\n",
    "theta5,cost_history5,theta_history5 = gradient_descent(X_train, y_train, theta, lr5, n_iter)\n",
    "plt.plot(range(n_iter), cost_history5, 'g.', label = 'learning rate 0.3')\n",
    "\n",
    "# Min cost line based on experimental run. Value of y has to be changed accordingly\n",
    "plt.axhline(y = 10.7, color = 'r', linestyle = '--', label = 'Min cost')\n",
    "\n",
    "plt.xticks(np.arange(0, n_iter+1, 50))\n",
    "plt.title(\"Cost vs iterations\")\n",
    "plt.legend(fontsize = 'x-large', markerscale = 3)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55dbc5d5",
   "metadata": {},
   "source": [
    "Note: If learning rate is too high (beyond 0.5 in this case), the cost increases exponentially. Shown below is learning rate of 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffaf8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate of 0.55\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "n_iter = 30\n",
    "theta = np.zeros((len(X_train[0]),1))\n",
    "\n",
    "lr6 = 0.55\n",
    "theta6,cost_history6,theta_history6 = gradient_descent(X_train, y_train, theta, lr6, n_iter)\n",
    "plt.plot(range(n_iter), cost_history6, 'b.', label = 'learning rate 0.55', markersize = 25)\n",
    "\n",
    "# Min cost line based on experimental run. Value of y has to be changed accordingly\n",
    "plt.axhline(y = 10.7, color = 'r', linestyle = '--', label = 'Min cost')\n",
    "\n",
    "plt.xticks(np.arange(0, n_iter+1, 1))\n",
    "plt.title(\"Cost vs iterations\")\n",
    "plt.legend(fontsize = 'x-large')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d404e",
   "metadata": {},
   "source": [
    "## Task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = reg.predict(X_train)\n",
    "print(\"\\nTrain RMSE using sklearn linear regression model:\",\n",
    "round(np.sqrt(mean_squared_error(y_train, y_pred_train)),3))\n",
    "print(\"\\nTrain R2 using sklearn linear regression model:\",\n",
    "round(r2_score(y_train, y_pred_train),3))\n",
    "\n",
    "y_pred_test = reg.predict(X_test)\n",
    "print(\"\\nTest RMSE using sklearn linear regression model:\",\n",
    "round(np.sqrt(mean_squared_error(y_test, y_pred_test)),3))\n",
    "print(\"\\nTest R2 using sklearn linear regression model:\",\n",
    "round(r2_score(y_test, y_pred_test),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
